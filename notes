Linear Regression 

Can modify to Binary Classification by letting > 0 -> 1, <= 0 -> -1

Goal:
    Predict real valued function that can be expressed as linear combination of inputs.

Can be thought of as theta_T dot x + theta_0. This is some n ( dim(x) ) dimensional object in n+1-dimensional space on which you make predictions.

Perceptron (Binary Classification):     
    Iterate on input -> if we don't predict this correctly, then add this x to theta and y to theta_0 -> moves theta closer to x.

Trick to train on non-linearities: Any function is a linear combination of kth degree polynomials as k approaches inf. Therefore, just add new features to input space: x_j^i for all until k and for all j until n.


Proof of why Least Squared is best for linear regression: -> Maximum Likelihood Estimation
    Define likelihood of parameters as probability of getting data given parameters
    Since log is monotonic, we want to maximize log(likelihood)
    We make few key assumptions: 
        y = linearCombination(x) + error -> error is some noise 
        Assume error is IID from normal(0 , mu^2)
    Maximizing log(likelihood) comes out to same as minimize differences squared loss


    Use same idea to see logistic regression -> Since we want to classify points that are not linearly seperable
    Likelihood(theta) = prod(P(y | x , theta)) -> assume samples are iid
    Want to find theta such that probability of getting input given current theta is maximized 
    y is 0/1 -> our model says 1 with probability sigmoid(theta dot x) 
    p(y|x , theta) = sigmoid(theta dot x)^y * (1-sigmoid(theta dot x))^(1-y)
    log(l(theta)) = sum(log(P(y|x , theta))) = sum(ylog(sigmoid(theta dot x)) + (1-y)log(1 - sigmoid(theta dot x)))
    We want to maximize log(l(theta))

Above were examples of Discriminative learning algos -> make model to estimate P(y | x)

Another type of model is generative -> estimate P(x | y) and P(y). Then, using bayes rules, we can find P(y | x) = P(x|y)*P(y) / P(x), where P(x) = sum(P(x|y) * P(y)) across all y
Naive Bayes:
    Discrete data -> feature vector of booleans. -> Want to model p(x | y) and p(y). 
    Key assumption: 
        Assume each feature is conditionally independent of others -> Given the label y, probability of seeing a feature i is independent of seeing a feature j.
        This allows us to say P(x | y) = prod(P(x_i | y)) across all features. Now just using MLE and intuition, we can see that P(x_i = k | y = Y) should simply just be the proprtion of sample data that satisfy x_i = k and y = Y.
    Now we can efficiently answer queries

    Only problem: We have found P(x | y) by finding P(x_i=k , y = Y) for the sample. If we havent seen some feature in the sample, we would assign it 0 probability during test time.
    This not only casuses mathematical issues, but is also statistically not what we want -> we want it to have non zero low probability. 
    Trick: Using Laplace Smoothing
        add 1 to every feature you are counting on numerator and denominator -> this way the probability is never truly 1 or 0.
GDA Model:
    Gaussian Discriminant Analysis
    Assume each label's data is distributed gaussian with some mean mu_j and covariance sigma ( usually use same sigma for ALL labels )
    This means P(x | y = j) ~ N(mu_j , sigma).
    Our goal is to find values of mu_j , sigma that maximize the likelihood of sampling the data. -> MLE!
    This time, instead of using likelihood of parameters = P(y | x), we need to use likelihood of paramters = P(y , x) -> a joint distribution on y and x
    We can simply just plug in the values we saw above ( P(x|y) is gaussian, P(y) is multinomial ) and take derivatives.
    We get the intuitive results for optimal values of mu_j and sigma:
        mu_j = average( all points with label j )
        sigma = average ( cov of data point with its average label ) -> average( outerProduct(x_i - mu_j) )


Unsupervised Learning:
    No Labels for data. Find patterns

K - means:
        As name suggest, find k "means" for the data ( clusters ). 
        Simple algo:
            - Choose k centers to start ( randomly, randomly from the data, or k-means++ (below))
            - Color each data point with the center it is closest to
            - Reassign each center to the average of the colored points for that center
            - Repeat color + reassignment
        Problem with random:
            Even if we choose randomly from the data, if we choose 2 points belonging to the same "cluster" ( obviously we don't know any cluster because data is unlabled ), we converge to bad centers.
        Fix:
            k-means++ -> choose first center randomly, second center is point that is farthest away from all centers ( argmax(min dist to any center) )
            this spreads out starting centers more

Mixture of Gaussians Model:
    Goal: Density Estimation
    or in other words, find a model for P(x).

    Assume data is drawn from multiple (k) gaussians. Find mu_j, sigma_j for each gaussian and z_j ( latent random variable ) which is multinomial, telling you probability of each gaussian
    Intuitive expl of EM:
        We know from GDA:
            if we knew z_j, we could just use GDA to find best values of gaussians.
        So, if we can fix, z_j, find optimal values, and from those, find better values of z_j, and repeat, we will converge to at least local max ( of log likelihood )
    EM:
        Log liklihood can be lower bounded using Jensen's inequality -> using latent probability distribution
        Find tight lower bound, then maximize this lower bound, then repeat.
